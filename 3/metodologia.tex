\chapter{Metodología de la Investigación}



\section{Diseño de la investigación}

Según \cite{bk_sampieri2014metodologia}, los diseños experimentales se caracterizan por manipular y establecer relaciones de causa-efecto entre variables independientes y dependientes.

En esta investigación, se adopta un diseño experimental, ya que se busca establecer una relación entre las técnicas y modelos de aprendizaje profundo, específicamente redes neuronales convolucionales (CNN), y la detección automatizada de deterioros en pavimentos en Lima Metropolitana. Esto implica manipular los parámetros del modelo, así como las características de los datos utilizados, para analizar el impacto en la precisión y efectividad del sistema desarrollado.

\subsection{Alcance de la Investigación}

El alcance de la investigación incluye el diseño, entrenamiento y evaluación de un modelo CNN que permita clasificar imágenes de pavimentos de manera automática. Esto abarca:

Recolección y preparación del conjunto de datos de imágenes.
Implementación de técnicas de preprocesamiento y limpieza de datos.
Entrenamiento de modelos CNN con diferentes configuraciones.
Evaluación de la efectividad del modelo y comparación con métodos tradicionales de inspección visual.
El objetivo principal es contribuir a la optimización del mantenimiento vial, reduciendo costos y mejorando la seguridad vial mediante un sistema automatizado para la detección de deterioros.



\subsection{Tipo de la investigación}

Definido el diseño experimental, el tipo de investigación es experimental puro, ya que la variable independiente (técnicas y modelos de CNN) será manipulada para observar su impacto en la variable dependiente (precisión en la detección de deterioros). Esta manipulación incluye ajustes en los hiperparámetros del modelo, selección de características de las imágenes y técnicas de procesamiento de datos para optimizar los resultados.

Además, se realizarán iteraciones con diferentes configuraciones y subconjuntos del dataset, buscando maximizar métricas como precisión, recall y F1-score, indicadores clave del desempeño del modelo en la tarea de clasificación.

\subsection{Enfoque de la investigación}

De acuerdo con \cite{bk_sampieri2014metodologia}, el enfoque cuantitativo utiliza herramientas estadísticas y sigue un proceso estructurado y secuencial para medir variables y analizar relaciones entre ellas.

Esta investigación sigue un enfoque cuantitativo, ya que los resultados del modelo CNN serán evaluados mediante métricas estadísticas que permiten medir su rendimiento en la clasificación de imágenes de pavimentos. Las métricas empleadas, como precisión, recall, F1-score y curva ROC, servirán para evaluar de manera objetiva la efectividad del sistema propuesto.


\section{Población}

La población corresponde a imágenes de pavimentos urbanos en diversas condiciones de conservación, recolectadas en el contexto de la ciudad de Lima Metropolitana. Estas imágenes reflejan una variedad de tipos de deterioro comunes en pavimentos, como grietas y fisuras, que afectan la infraestructura vial.

\section{Muestra}

La muestra está constituida por un conjunto de 30,000 imágenes, clasificadas en dos categorías principales: con grietas y sin grietas. Estas imágenes fueron obtenidas por el autor Omoebamije Oluwaseun, utilizando un dron DJI Mavic 2 Enterprise para tomas aéreas y un smartphone para capturas a nivel del suelo. Las imágenes están en formato RGB, resolución 227x227 píxeles, y han sido etiquetadas previamente para su uso en tareas de clasificación mediante CNN.


\section{Operacionalización de Variables}

La operacionalización de las variables de esta investigación se describe en la Tabla \ref{tab:operacionalizacion_variables}, donde se especifican las dimensiones, indicadores y las fórmulas correspondientes para la medición de cada variable.

\begin{table}[H]
	\centering
	\caption{Operacionalización de variables para la Hipótesis General}
	\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|p{3cm}|}
	\hline
	\textbf{Variable} & \textbf{Definición Conceptual} & \textbf{Definición Operacional} & \textbf{Fórmula del Indicador} \\ \hline
	Implementación de un modelo automatizado basado en redes neuronales convolucionales (VI) & Uso de redes neuronales para la clasificación automatizada de deterioros en pavimentos. & Desarrollo, entrenamiento y validación de un modelo CNN para clasificar imágenes de pavimentos. & \(\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total}}\) \\ \hline
	Calidad en la detección de deterioros en pavimentos (VD) & Grado de acierto en la identificación de daños en pavimentos. & Porcentaje de detección correcta de los deterioros en un conjunto de datos de prueba. & \(\text{Sensibilidad} = \frac{\text{TP}}{\text{TP} + \text{FN}}\) \\ \hline
	Eficiencia en el mantenimiento de vías (VD) & Optimización de recursos para reparar vías. & Reducción en el tiempo y los costos asociados con la reparación de vías, basada en la clasificación automatizada. & \(\text{Tasa de mejora} = \frac{\text{Antes} - \text{Después}}{\text{Antes}}\) \\ \hline
	Seguridad vial (VD) & Reducción de accidentes relacionados con deterioros en las vías. & Número de accidentes evitados debido al mantenimiento oportuno basado en detecciones automatizadas. & \(\text{Proporción} = \frac{\text{Accidentes evitados}}{\text{Total accidentes previos}}\) \\ \hline
	\end{tabular}
	\end{table}
	
\begin{table}[H]
	\centering
	\caption{Operacionalización de variables para la Hipótesis Específica 1}
	\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|p{3cm}|}
	\hline
	\textbf{Variable} & \textbf{Definición Conceptual} & \textbf{Definición Operacional} & \textbf{Fórmula del Indicador} \\ \hline
	Uso de redes neuronales convolucionales (VI) & Uso de algoritmos CNN para procesar imágenes y clasificarlas. & Entrenamiento de una red neuronal convolucional para clasificar imágenes en ``deterioradas'' y ``no deterioradas''. & \(\text{Precisión del modelo} = \frac{\text{Correctas}}{\text{Total clasificadas}}\) \\ \hline
	Precisión en la clasificación del estado de los pavimentos (VD) & Nivel de exactitud en la identificación del estado de los pavimentos. & Porcentaje de coincidencia entre la predicción del modelo y las etiquetas reales del conjunto de prueba. & \(\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total}}\) \\ \hline
	\end{tabular}
\end{table}

		
\begin{table}[H]
	\centering
	\caption{Operacionalización de variables para la Hipótesis Específica 2}
	\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|p{3cm}|}
	\hline
	\textbf{Variable} & \textbf{Definición Conceptual} & \textbf{Definición Operacional} & \textbf{Fórmula del Indicador} \\ \hline
	Detección automatizada en tiempo real (VI) & Uso de modelos para identificar daños de manera inmediata. & Implementación de sistemas de detección que procesen datos en tiempo real para clasificar imágenes de pavimentos. & \(\text{Tiempo promedio} = \frac{\text{Total tiempo}}{\text{N imágenes}}\) \\ \hline
	Tiempo de respuesta para reparaciones (VD) & Lapso entre la identificación de daños y su reparación. & Medición en días u horas entre la detección del deterioro y la acción correctiva. & \(\text{Reducción} = \frac{\text{Tiempo antes} - \text{Tiempo después}}{\text{Tiempo antes}}\) \\ \hline
	Costos de mantenimiento a largo plazo (VD) & Gasto total asociado a reparaciones preventivas y correctivas en un periodo. & Comparación de los costos acumulados entre métodos tradicionales y el sistema automatizado. & \(\text{Diferencia} = \text{Costo Tradicional} - \text{Costo Automatizado}\) \\ \hline
	\end{tabular}
\end{table}
			
\begin{table}[H]
	\centering
	\caption{Operacionalización de variables para la Hipótesis Específica 3}
	\begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|p{3cm}|}
	\hline
	\textbf{Variable} & \textbf{Definición Conceptual} & \textbf{Definición Operacional} & \textbf{Fórmula del Indicador} \\ \hline
	Priorización de zonas más deterioradas (VI) & Identificación de áreas críticas para reparación con base en el nivel de daño. & Uso del modelo CNN para asignar prioridad a las áreas con mayores índices de deterioro. & \(\text{Índice de prioridad} = \frac{\text{Deterioro}}{\text{Área total}}\) \\ \hline
	Eficiencia en la asignación de recursos (VD) & Optimización del uso de personal, materiales y tiempo en función de las prioridades detectadas. & Comparación de recursos asignados antes y después de implementar el modelo automatizado. & \(\text{Tasa de eficiencia} = \frac{\text{Producción después}}{\text{Recursos después}}\) \\ \hline
	\end{tabular}
\end{table}
				

\noindent
Las fórmulas de los indicadores son las siguientes:
\begin{itemize}
    \item \textbf{Precisión (Accuracy)}: Relación entre predicciones correctas y el total de predicciones. 
    \[
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
    \]
    \item \textbf{Recall (Sensibilidad)}: Proporción de verdaderos positivos respecto a todas las muestras positivas. 
    \[
    Recall = \frac{TP}{TP + FN}
    \]
    \item \textbf{F1-score}: Media armónica de precisión y recall. 
    \[
    F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
    \]
    \item \textbf{ROC-AUC}: Área bajo la curva ROC, calculada mediante integración numérica de los valores de TPR y FPR a diferentes umbrales.
    \item \textbf{Eficiencia computacional}: Evaluada a través del tiempo de entrenamiento (en segundos o minutos) y la memoria utilizada (en GB o MB).
\end{itemize}


\section{Técnicas de Recolección de Datos}

En la presente investigación, las técnicas de recolección de datos empleadas son las siguientes:

\begin{itemize}
    \item \textbf{Obtención del dataset:} Se utilizaron fuentes secundarias para recolectar un conjunto de datos previamente elaborado, específicamente el dataset titulado *Concrete and Pavement Crack Dataset*. Este dataset contiene imágenes de superficies de concreto y pavimento clasificadas en dos categorías: con grietas y sin grietas. Las imágenes fueron recopiladas mediante el uso de un dron DJI Mavic 2 Enterprise y un smartphone, con una resolución de 227 x 227 píxeles en formato RGB.
    \item \textbf{Validación del dataset:} Antes de su uso, el dataset fue revisado para garantizar que todas las imágenes cumplan con los estándares de calidad necesarios, verificando la clasificación correcta de las categorías (crack y non-crack).
    \item \textbf{Preparación de los datos:} Se realizaron procesos de preprocesamiento para adaptar los datos al entrenamiento del modelo de redes neuronales convolucionales (CNN), incluyendo la normalización, el cambio de tamaño de las imágenes y la división del dataset en conjuntos de entrenamiento, validación y prueba.
\end{itemize}

Estas técnicas aseguran la correcta disposición y calidad de los datos para el análisis y entrenamiento del modelo.


\section{Técnicas para el Procesamiento y Análisis de Información}

El procesamiento y análisis de la información se llevó a cabo mediante el uso de técnicas basadas en aprendizaje profundo y análisis estadístico. Los pasos seguidos fueron los siguientes:

\begin{itemize}
    %%falta item de adquisición
	\item \textbf{Adquisición del dataset:} El conjunto de datos utilizado para entrenar y evaluar el modelo será obtenido mediante una recopilación de imágenes de pavimentos en Lima Metropolitana, capturadas a través de drones, cámaras móviles o bases de datos públicas. Estas imágenes serán procesadas y etiquetadas manualmente para su clasificación en diferentes tipos de deterioros.
	\item \textbf{Preprocesamiento:} Las imágenes fueron sometidas a procesos de normalización y aumento de datos (\textit{data augmentation}) para mejorar la calidad y diversidad del dataset.
    \item \textbf{Entrenamiento del modelo:} Se entrenaron redes neuronales convolucionales (CNN) utilizando el conjunto de entrenamiento del dataset. Durante este proceso, se ajustaron los hiperparámetros clave, como la tasa de aprendizaje y el tamaño del lote.
    \item \textbf{Validación y ajuste:} Se utilizó el conjunto de validación para ajustar los hiperparámetros del modelo y prevenir el sobreajuste.
    \item \textbf{Evaluación:} El modelo final fue evaluado con el conjunto de prueba utilizando métricas de rendimiento como precisión (\textit{accuracy}), sensibilidad (\textit{recall}), y F1-score.
\end{itemize}

El flujo del proceso se ilustra en el Diagrama %\ref{fig:procesamiento_analisis}.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=1.00\textwidth]{2/figures/diagrama.png}
		\caption[Diagrama del procesamiento y análisis de la información]{Diagrama del procesamiento y análisis de la información. \\
		Fuente: Elaboración propia.}
		%\label{3:fig301}
	\end{center}
\end{figure}





%\section{Metodología de Implementación de la Solución}












\begin{comment}
La metodología por seguir para implementar un modelo de Deep Learning está basado en gran medida en el conocido ciclo de vida de desarrollo de modelos de Inteligencia Artificial, del cual gran parte de los antecedentes mostrados anteriormente siguen con algunas variaciones. 

En el presente caso, se pretende desarrollar un modelo de Deep Learning capaz de brindar ayuda en el diagnóstico médico; por tal motivo, se optó por basar metodología de esta investigación en la de \cite{pr_monroy2021disvc}, modificándolo en cierta medida en el contexto de nódulos tiroideos e imágenes de ultrasonido. En la Figura \ref{3:fig301} se presenta de forma gráfica la metodología a seguir.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=1.00\textwidth]{3/figures/metod_classthy1.png}
		\caption[Metodología de implementación]{Metodología de implementación. \\
		Fuente: Elaboración propia.}
		\label{3:fig301}
	\end{center}
\end{figure}

La adquisición del conjunto de datos, es decir, imágenes de ultrasonido, consiste en la búsqueda y revisión de las bases de datos sobre imágenes de nódulos tiroideos, donde finalmente se seleccionará y descargará la de mayor utilidad. La base de datos debe cumplir con ciertos requerimientos para realizar un posterior entrenamiento del modelo que otorgue buenos resultados. Las imágenes deben ser debidamente etiquetadas según el carácter del nódulo al que representen, es decir, se debe indicar si cada una de las imágenes pertenece a la categoría benigno o maligno. Además, para evitar discrepancias entre calidad de imágenes en futuras evaluaciones, el conjunto de datos debe poseer imágenes de distintas instituciones de salud y de distintas calidades. Esto permitirá que el modelo entrenado no dependa de la una alta o baja calidad de las imágenes para realizar una correcta predicción. Finalmente, la cantidad de datos debe ser relativamente alta con el fin de aumentar la capacidad de generalización del modelo y evitar posibles sobreajustes o bajo rendimiento.  

En la etapa de preprocesamiento, se realizará en primera instancia una exploración del conjunto de datos con el fin de entender su composición y las características a mejorar; por ejemplo, un posible desbalanceo de clases o presencia de imágenes corruptas o sin etiquetar. Posteriormente, se realizará limpieza datos en caso de imágenes corruptas o de nula utilidad. Además, se usarán técnicas de Aumento de Datos en la situación de desbalanceo de datos, con el fin de evitar una baja generalización y sobreajuste en la clase mayoritaria. Además, se aplicará un redimensionamiento y normalización en las imágenes destinadas al entrenamiento del modelo con el objetivo de reducir la complejidad computacional y así obtener menor tiempo de ejecución.

Una vez se tenga la data ya preprocesada, una parte de este se usará para el entrenamiento de modelos de Deep Learning. Inicialmente, se planea usar algunos de los diversos tipos y arquitecturas de Redes Neuronales Convolucionales (CNN), específicamente los más utilizados en este tipo de tareas como lo son VGG y ResNet, pues son ideales para la extracción de características de las imágenes, facilitando así el proceso final de clasificación. Además, se desarrollarán modelos basados en arquitecturas de Vision Transformer debido al potencial que han demostrado en anteriores investigaciones. Finalmente, también se realizará el desarrollo de modelos híbridos de CNN con Vision Transformer. %similares a los descritos por \cite{pr_JERBI2023autoclassViTGAN}.

Cada uno de los modelos será probado en la parte restante de la data, específicamente en la data de prueba o test. De aquí se obtendrán las predicciones de los modelos clasificando las imágenes en benigno (0) o maligno (1).

\section{Metodología para la Medición de Resultados de la Implementación}

Los resultados obtenidos de la clasificación de los modelos previamente entrenados deberán ser evaluados para una correcta elección final. 

Antes de presentar las métricas a usar, es necesario conocer a la matriz de confusión y las partes que lo conforman, pues servirá como base para entenderlas. 

Según \cite{ws_izco2018bdcp} la matriz de confusión es una herramienta que permite ver de forma más clara el rendimiento de nuestro modelo. Este se presenta en la Figura \ref{3:fig302}.

\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.75\textwidth]{3/figures/conf_matrix.jpg}
		\caption[Matriz de Confusión]{Matriz de Confusión. \\
		Fuente: Elaboración propia.}
		\label{3:fig302}
	\end{center}
\end{figure}

La matriz consta de cuatro partes importantes: TP, FP, FN y TN. Estos serán usados para presentar las fórmulas de las métricas más adelante. El primero (TP o true positive) se refiere a la cantidad de observaciones que se han predicho como positivos y que en verdad sí son positivos; por el contrario, FP (false positive) se refiere a aquellas predicciones dadas como positivos, pero en verdad son negativos. FN (false negative) es la cantidad de observaciones predichas como negativas; sin embargo, estas en realidad son positivas. Finalmente, TN (true negative) es la cantidad de observaciones predichas como negativas y que en realidad son también negativas.

A continuación, se presenta las métricas para medir el desempeño de la clasificación del modelo.

El accuracy representa aquella proporción del total de predicciones que se ha obtenido correctamente \parencite{ws_izco2018bdcp}. Este se calcula a través de la siguiente fórmula 1.

%\begin{equcaption}[!ht]
\begin{equation}\label{eq:accuracy}
\phantomsection
accuracy=\frac{TP+TN}{TP+TN+FP+FN}
\end{equation}
\myequations{Fórmula para calcular el accuracy}

El recall representa la proporción de solo los positivos reales predichos de manera acertada \parencite{ws_izco2018bdcp}. Se calcula con la siguiente fórmula.

%\begin{equcaption}[!ht]
\begin{equation}\label{eq:recall}
\phantomsection
recall=\frac{TP}{TP+FN}
\end{equation}
\myequations{Fórmula para calcular el recall}

Precision representa aquella proporción de lo predicho positivamente que es positiva \parencite{ws_izco2018bdcp}. Se calcula con la fórmula a continuación.

%\begin{equcaption}[!ht]
\begin{equation}\label{eq:precision}
\phantomsection
precision=\frac{TP}{TP+FP}
\end{equation}
\myequations{Fórmula para calcular el precision}

\begin{landscape}
	\section{Cronograma de actividades y presupuesto}
	Se propuso un cronograma para la investigación. Conforma desde el inicio hasta ser terminada con la sustentación final planeada para mediados del año 2024. Este se presneta en la Figura \ref{3:fig303}.

	\begin{figure}[!ht]
		\begin{center}
			\includegraphics[width=1.50\textwidth]{3/figures/cronograma_tesis_thyr.jpg}
			\caption[Cronograma de actividades]{Cronograma de actividades.\\
				Fuente: Elaboración propia.}
			\label{3:fig303}
		\end{center}
	\end{figure}
	
\end{landscape}

Además, se determinó el presupuesto necesario para la elaboración completa de la investigación. Este se presenta en la Tabla \ref{3:table1}.

\begin{table}[H]
	\caption[Presupuesto]{Presupuesto.}
	\label{3:table1}
	\centering
	\small
	\begin{tabular}{llll}
		\specialrule{.1em}{.05em}{.05em}
		{Grupo} & {Item} & {Costo (soles)} & {Subtotal} \\
		\specialrule{.1em}{.05em}{.05em}
		\multirow{2}{4cm}{Recursos materiales} & {Laptop} & {S/ 6,500.00} & {} \\
		{} & {Materiales de escritorio} & {S/ 100.00} & {S/ 6,600.00} \\
		\cline{1-4}
		\multirow{2}{4cm}{Software y trámites} & {Matrícula de Trabajo de Tesis II} & {S/ 375.00} & {} \\ % & {Reserva de tema} & {S/ 2,700.00} & {} \\
		{} & {Cuotas de Trabajo de Tesis II} & {S/ 1,044.00} & {} \\
		%{} & {Derecho de inscripción} & {S/ 800.00} & {} \\
		%{} & {Derecho de sustentación} & {S/ 1,500.00} & {} \\
		{} & {Software} & {S/ 50.00} & {} \\
		{} & {Renta de servidor en la nube} & {S/ 224.15} & {S/ 1,693.15} \\ % & {S/ 5,274.15} \\
		\cline{1-4}
		\multirow{2}{4cm}{Extras} & {Consultorías} & {S/ 100.00} & {} \\
		{} & {Movilidad} & {S/ 200.00} & {S/ 300.00} \\
		\specialrule{.1em}{.05em}{.05em} 
		{} & {Total} & {} & {S/ 8,593.15} \\ % & {S/ 12,174.15} \\
		\specialrule{.1em}{.05em}{.05em}
	\end{tabular}
	\begin{flushleft}	
		\small Fuente: Elaboración propia.
	\end{flushleft}
\end{table}

\end{comment}

